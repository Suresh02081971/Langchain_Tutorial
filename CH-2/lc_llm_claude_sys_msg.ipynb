{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f2d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "import os\n",
    "\n",
    "# Set your API key\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Initialize Claude\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "# Example 1: Coding Assistant\n",
    "print(\"Example 1: Coding Assistant\")\n",
    "print(\"-\" * 60)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert Python programmer. Provide concise, well-commented code examples.\"),\n",
    "    HumanMessage(content=\"How do I read a JSON file in Python?\")\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Example 2: Different Personality/Tone\n",
    "print(\"Example 2: Pirate Personality\")\n",
    "print(\"-\" * 60)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant who speaks like a pirate. Be friendly and informative.\"),\n",
    "    HumanMessage(content=\"What's the weather like today?\")\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Example 3: Expert in Specific Domain\n",
    "print(\"Example 3: Medical Expert (Informational)\")\n",
    "print(\"-\" * 60)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a medical professional providing general health information. Always remind users to consult their doctor for personal medical advice.\"),\n",
    "    HumanMessage(content=\"What are the benefits of regular exercise?\")\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Example 4: Multi-turn Conversation with Context\n",
    "print(\"Example 4: Multi-turn Conversation\")\n",
    "print(\"-\" * 60)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful tutor teaching mathematics. Be patient and explain step-by-step.\"),\n",
    "    HumanMessage(content=\"Can you explain what a derivative is?\"),\n",
    "    AIMessage(content=\"A derivative measures how a function changes as its input changes. It tells us the rate of change or slope at any point.\"),\n",
    "    HumanMessage(content=\"Can you give me a simple example?\")\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Example 5: Output Format Control\n",
    "print(\"Example 5: Structured Output Format\")\n",
    "print(\"-\" * 60)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant. Always respond in bullet points with clear headings.\"),\n",
    "    HumanMessage(content=\"What are the main features of Python?\")\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Example 6: Role-Specific Constraints\n",
    "print(\"Example 6: Technical Writer with Constraints\")\n",
    "print(\"-\" * 60)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a technical writer. Explain concepts clearly using analogies. Keep responses under 100 words.\"),\n",
    "    HumanMessage(content=\"Explain what cloud computing is\")\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Example 7: Combination of Multiple Instructions\n",
    "print(\"Example 7: Multiple System Instructions\")\n",
    "print(\"-\" * 60)\n",
    "messages = [\n",
    "    SystemMessage(content=\"\"\"You are a helpful coding mentor with these traits:\n",
    "    - Provide Python code examples\n",
    "    - Explain code line-by-line\n",
    "    - Suggest best practices\n",
    "    - Keep explanations beginner-friendly\"\"\"),\n",
    "    HumanMessage(content=\"Show me how to handle exceptions in Python\")\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Example 8: Building a Conversation Dynamically\n",
    "print(\"Example 8: Dynamic Conversation Building\")\n",
    "print(\"-\" * 60)\n",
    "conversation = [\n",
    "    SystemMessage(content=\"You are a helpful shopping assistant. Help users find products and answer questions.\")\n",
    "]\n",
    "\n",
    "# Simulate a conversation\n",
    "user_queries = [\n",
    "    \"I'm looking for a laptop for programming\",\n",
    "    \"What specs should I look for?\",\n",
    "    \"What's a good budget range?\"\n",
    "]\n",
    "\n",
    "for query in user_queries:\n",
    "    conversation.append(HumanMessage(content=query))\n",
    "    response = llm.invoke(conversation)\n",
    "    conversation.append(AIMessage(content=response.content))\n",
    "    print(f\"User: {query}\")\n",
    "    print(f\"Assistant: {response.content}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
